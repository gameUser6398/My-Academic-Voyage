

这非常适合self-Attention机制.



分区 个人心得 的第 245 页

中期答辩

2023年9月28日

11:22



1.

2.

3.

4.

能不能把ESM表征结果与模型结果作一个对比

利用self-Attention，把残基之间的关系捕获。可以以单一肽链、多条肽链（空间结

构）活性中心关键氨基酸之间的联系。

能不能把mf、bp、cc三功能拆开。对嵌入采用不同的策略。

精细预训练

迁移学习、嵌入、蛋白质序列-结构差距等等名词，可以参考ProtTrans论文

基因本体论：(cid:13583)一生物学的工具

来(cid:14362) <https://www.nature.com/articles/ng0500_25>

各位老师好，我是刘畅乐，我们项目的主题是基于深度学习的蛋白质功能预测

此次(cid:2125)报主要分为5个部分。

我们项目的初心是开发一种不依赖于序列相似性的深度模型、能够较好实现远缘蛋白的功能预

测

项目主要分为4个阶段。第一阶段进行了软硬件的学习，第二阶段参加了CAFA5挑战赛，第三

阶段才真正明确项目的出发点，制定了技术路线，第四阶段是基于生物信息学的顶级预测方法

启发，融合多模态数据，来提高模型性能上限。

此次(cid:2125)报主要关注第二三阶段。

在CAFA5挑战赛中，我们设计了一个卷积神经网络，实现了74.46%的准确率，但最终成绩并

不理想。我们反思，这是卷积神经网络受到卷积核的大小限制，只能提取局部序列的特征。我

们寄希望于Transformer构架，它在机器翻译任务上表现惊人。所以我们改造它，希望捕获远

距离氨基酸之间的相互作用。但事实是效果并不好，我们在CAFA论坛里找到(cid:1710)多信息。发现

根本原因是我们不是人工智能专业的、不会设计深度学习模型。为此项目陷入了迷茫期，成员

变更就发生在这一时期。此时的我们，迫切需要可操作的、可优化的模型作为项目的原型。我

们在CAFA论坛上获取大量信息，通过文献检索，我们找到了TALE模型，

它是一个非预训练模型，这意味着它在计算资源上、能力水平上是我们可改造的。TALE的创

新点在于利用GO术语嵌入，通过点积的方式，衡量每个氨基酸对GO的贡献。所以我们开始

研究它，重新编写它。

