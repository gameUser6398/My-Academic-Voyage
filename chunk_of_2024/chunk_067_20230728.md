

把文字顺序转换为LSTM输入的数据

LSTM原理动画解释_哔哩哔哩_bilibili

遗忘门

输入门

输出门



分区 基础知识 的第 158 页

分区 基础知识 的第 159 页

RNN-LSTM生成名称
20:20

2023年7月28日

从头开始的 NLP：使用字符级 RNN 生成名称 — PyTorch 教程 2.0.1+cu117 文档

文件在/home/lcl/tutorial_RNN/
nn.LSTM

根据单个字符预测下一个字符，每次都要根据output求loss，然后加起来

(cid:2124)LOSS错误示范：

正确示范：

分区 基础知识 的第 160 页

LSTM改进1：辣鸡，问题在layer_size错误、loss计算错误

分区 基础知识 的第 161 页

记录：

1.

2.

3.

今天的rnn模型损失不稳定，原因是category_tensor创建时少一行代码，category_tensor全变成0了，也

就是没有添加种类信息。

RNN类的forward返回hidden，cell，output。output必要的原因是(cid:2124)loss

训练的策略(cid:1710)重要，原版hidden用了两次，LSTM用经典的，显然种类信息没有含进去，<EOS>也没能预

测出。

LSTM改进2：loss波动较大     4-lstm 。py

分区 基础知识 的第 162 页

结合 CNN 和 RNN – 疯狂还是天才？- DataScienceCentral.com

分区 基础知识 的第 163 页

self-attention机制

2023年8月1日

18:26