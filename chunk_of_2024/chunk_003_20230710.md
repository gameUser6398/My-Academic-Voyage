分区 项目进展 的第 3 页

各自使用用户lcl、xk、zlj，文件储存在/home/usr（用户名）内

root用户一般不用，/root

参考书

1.

人民邮电出版社《python深度学习》——keras库讲解】

AI for sicience

分区 项目进展 的第 4 页

7月7日、8日
19:56

2023年7月10日

caaaaaatcat！:

今天三个部分：

1 账号

2 环境

3 词嵌入

赵:

我已经整理完了模型构建的基本过程和后期的预测，可以再带大家串一遍，然后就可以开始构建了

caaaaaatcat！:

2:00 开讲

18:50 词嵌入结束，文献讲解

38:40 系统界面介绍

caaaaaatcat！:

链接：https://pan.baidu.com/s/1w5PKWo5elODkVxiH7XSbCQ?pwd=p5hr

提取码：p5hr

caaaaaatcat！:

今天是下载数据、bio_embedding库初识，有几个概念要区分一下：

1. 储存词向量的h5文件。下载了人类蛋白组词向量、用bio_embedding读取。h5文件的来源

（ProtT5语言模型的副产物）、它的意义（暂不清楚）

2. per-protein与per-residue嵌入的区别（咱不清楚），但后者文件大小是前者的数百倍

3. bio_embedding库。它整合了word2vec、BERT等等生成词向量的工具，与有Transformer模型。

caaaaaatcat！:

下周一晚上我们讨论：

1. bio_embedding对应的多篇论文（赵）

2. 词向量的构建（刘）

3. CNN的收尾（胥）

4. pytorch初识（刘）

caaaaaatcat！:

分区 项目进展 的第 5 页

caaaaaatcat！:

上面说错了，只有一篇（只讲和词向量有关的部分）
https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.113

分区 项目进展 的第 6 页

7-10
2023年7月10日

19:58

刘：

1.

2.

3.

环境

h5文件的读取——嵌入结果

torch张量、神经网络的类别

胥：CNN参数、细节

1.

2.

3.

4.

5.

6.

channel的含义。

核函数。

层数选多少合适

语言类、蛋白质padding怎么填充

多个维度，shape

保底机制（）

分区 项目进展 的第 7 页

7-11
2023年7月10日

22:11

刘：

1.

2.

3.

bio_embedding配置结束

"Protocol4_Classifier_embd.py" MLP+Embedding预测准确率0.71。

Protocol3_2DVisual_basic.html 绘制亚细胞定位投影图。

问题：

1.

parameters={'hidden_layer_sizes':[(30,),(20,15)]} size怎么说

hidden_layer_sizes :例如hidden_layer_sizes=(50, 50)，表示有两层隐藏层，第一

层隐藏层有50个神经元，第二层也有50个神经元。

2.

3.

4.

来(cid:14362) <https://blog.csdn.net/u011311291/article/details/78743393>

Nearest Neighbor Search画图时？邻居？迭代

classifiers与classifier的数量计算，2x3=6
权重。为了加快处理速度，我们从这里下载了监督亚细胞定位和二级结构预测模型的模

型权重

来(cid:14362) <https://docs.bioembeddings.com/v0.2.3/notebooks/extract_supervised_from_seqvec.html>

胥：

1.

CNN代码

赵:
1.

分区 项目进展 的第 8 页

7-13
2023年7月11日

21:38

刘：BERT模型、bio_embedding

胥：pytorch

赵：来(cid:14362) <https://academic.oup.com/bioinformatics/article/38/8/2102/6502274?login=true>

1.

pre-training fine-tuning。预训练（pre-training/trained）和微调（fine-

tuning） - 知乎 (zhihu.com)

Bert和BiLSTM的，好在哪里

解冻、卷积

2.

3.

4.

深度学习基本功2：网络训练小技巧之使用预训练权重、冻结训练和断点恢复 - 知乎
(zhihu.com)

5.

教你深入理解“预训练” - 知乎 (zhihu.com)

Bert这么训练方法，与序列相似性有什么本质的区别？

分区 项目进展 的第 9 页

7-15
2023年7月14日

19:15

刘：

1.

2.

RI越大越好吗

linear是两层（√）

赵：

多条肽链的蛋白质的预测

抗体基因重拍的预测

分区 项目进展 的第 10 页

CAFA阅读

2023年7月17日

20:48