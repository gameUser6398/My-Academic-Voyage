分区 基础知识 的第 216 页

函数代码

2024年5月7日

10:34



1.

2.

3.

torch.contiguous()
contiguous一般与transpose，permute，view搭配使用：使用transpose或permute进行维度变
换后，调用contiguous，然后方可使用view对维度进行变形（如：
tensor_var.contiguous().view() ），示例如下：
x=torch.Tensor(2,3)y=x.permute(1,0)# permute：二维tensor的维度变换，此处功能相当于转置
transposey.view(-1)# 报错，view使用前需调用contiguous()函数y=x.permute(1,0).contiguous()
y.view(-1)# OK

来自 <https://zhuanlan.zhihu.com/p/64376950>

torch.nn.conv1d()
为什么CNN中的卷积核一般都是奇数*奇数，没有偶数*偶数的？

来自 <https://www.zhihu.com/question/51603070>

torch.cuda.is_available()----- to(device)
PyTorch如何使用GPU，训练神经网络时哪些东西可以传到GPU运算_能不能在bml codelab导入

torch-CSDN博客

4.

乘法：torch.bmm()与torch.matmul()

都是叉乘，区别在于后者对shape要求更宽泛

5.

DataLoader中的shuffer=Ture表示在每一次epoch中都打乱所有数据的顺序，然后以

batch为单位从头到尾按顺序取用数据。这样的结果就是不同epoch中的数据都是乱序

的。

来自 <https://blog.csdn.net/qq_44901346/article/details/115770988>

6.

nn.BatchNorm1d

不改变shape，
来自 <https://blog.csdn.net/qq_40671063/article/details/126984314>

7.

lora带来的错误
发生异常: TypeError
forward() got an unexpected keyword argument 'labels'
File "/mnt/data/liuchangle/AMR/ARG-DRSN/src-lora_esm/model.py", line 123, in forward
seq_embeds = self.base_model(input_ids=input_ids, File "/mnt/data/liuchangle/AMR/ARG-
DRSN/src-lora_esm/train.py", line 96, in compute_loss logits = model(**inputs) File
"/mnt/data/liuchangle/AMR/ARG-DRSN/src-lora_esm/train.py", line 178, in
train_protein_model trainer.train() File "/mnt/data/liuchangle/AMR/ARG-DRSN/src-
lora_esm/train.py", line 228, in <module> train_protein_model() TypeError: forward()
got an unexpected keyword argument 'labels'

trainer的要求

