分区 文献阅读 的第 86 页

MLS 类别，92.38% 的基因对所有三类抗生素都具有耐药性。分配给73 938个未经审查的ARG的具体阻力类别及其预测概率值已在 附
表S2.

此外，我们计算了 73 938 个未经审查的 ARG 与我们的 PLM-ARGDB 之间的同一性，发现其中 64.77% 的相似度为 <40%，它们被定义

为遥远的同源 ARG。我们发现，这些遥远的同源ARG中有58%可以用PLM-ARG预测。值得注意的是，29.67%的ARGs具有<20%的相似性。

这些结果进一步证明了PLM-ARG在ARG识别方面的强大能力（图5D）。类别分类也具有很高的可靠性。例如，UniProt蛋白A0A010ZRL4

与参考ARGs的相似度<20%，被预测为四环素。它的功能在UniProt数据库中被记录为四环素耐药元件的阻遏因子。除此之外，UniProt

桑基图

蛋白A0A023CZL5与参考 ARG 的相似性<20%，被预测为肽。据记载，其功能参与对阳离子抗菌肽的耐药机制。

来自 <https://academic.oup.com/bioinformatics/article/39/11/btad690/7443986?login=true >

四.

补充材料：宏基因组抗性基因多样性调查
To further demonstrate the utility of PLM-ARG and explore the resistome diversity of various earth’s environmental
microbiota, we randomly selected 100 samples of seven different environments (e.g., human gut, skin, building,
wastewater, marine, and freshwater).
We then employed our developed PLM-ARG model to identify potential ARGs from the 52,515 MAGs （宏基因组组装基因

组）and conducted a diversity analysis of ARG across different environmental conditions.

结论：

•
•
•

the building samples harbored the highest proportion of ARGs, followed by the skin and human gut samples
samples obtained from different environments were significantly separated
soil samples were the most variable in ARG composition. In contrast, the human gut and wastewater samples
variable was less than those obtained from other environments.

五.

局限

虽然这项研究只关注获得性基因，但重要的是要承认基因点突变引起的抗性与获得性基因有很大不同。因此，识别由点突变引起的耐

药性对于理解细菌耐药性的机制至关重要，应该在未来的研究中受到更多关注。

2023 年用于评估和监测使用情况的

六.
•

代码阅读
train.py
from xgboost import XGBClassifier
from utility import extract, get_label
from sklearn.multioutput import MultiOutputClassifier

# ESM-1b加载
model, alphabet = load_model_and_alphabet_local('models/e sm1b_t33_650M_UR50S.pt')

# 数据加载
seq_id, embedding_res = extract(in_fasta, alphabet, model, repr_layers = [32],
                                     batch_size = batch_size, max_len= maxlen)
Label_ID, ARG_Category = get_label(seq_id)
np.savetxt(cat_index, ARG_Category, delimiter=",", fmt='%s')

# 1. train model for ARG identification
model1 = XGBClassifier(learning_rate=0.1, objective='binary:logistic',
                            max_depth = 7, n_estimators = 200)
# X中有阴性和阳性样本ARG_X，Y第一列？判断是否是ARG
model1.fit(X, Y[:,0])

# 2. Training for resistance category classification
model2 = MultiOutputClassifier(XGBClassifier(learning_rate=0.1,
                                                     objective='binary:logistic',
                                                     max_depth = 7, n_estimators = 200))
# ARG_Y有多列？分别表示ARG, freq_id, rare_id, multi_drug_id, others_undefined_id
model2.fit(ARG_X, ARG_Y)
joblib.dump(model2, cat_model)

•

utility.py
from esm import FastaBatchedDataset, pretrained
from torch.utils.data import DataLoader
from sklearn.preprocessing import MultiLabelBinarizer

# 替换稀有氨基酸为X
def AA_replace(seq):

#
def extract(fasta_file, alphabet, model,repr_layers=[32], batch_size=500, max_len = 200):
    dataset = FastaBatchedDataset.from_file(fasta_file)
    seq_num = len(dataset.sequence_labels)
    # 氨基酸替换
    for i in range(seq_num):
        dataset.sequence_strs[i] = AA_replace(dataset.sequence_strs[i])

    # 划分批次
    N = ceil(seq_num/batch_size)
    batches = []
    for k in range(N):
        n = k*batch_size
        batches.append(list(range(n, min(n+batch_size, seq_num))))

    if torch.cuda.is_available():
        model = model.cuda()
        print("Transferred model to GPU")
    data_loader = DataLoader(dataset, collate_fn=alphabet.get_batch_converter(),batch_sampler=batches)
    print(f"Read {fasta_file} with {len(dataset)} sequences")

    repr_layers = [min(i, model.num_layers) for i in repr_layers]

    result = {layer:torch.empty([0, ]) for layer in repr_layers}
    seq_id = []
    with torch.no_grad():
        for batch_idx, (labels, strs, toks) in enumerate(data_loader):
            print(f"Processing {batch_idx + 1} of {len(batches)} batches ({toks.size(0)} sequences)")
            # The model is trained on truncated sequences and passing longer ones in at
            # infernce will cause an error. See https://github.com/facebookresearch/esm/issues/21
            toks = toks[:, :max_len]
            out = model(toks, repr_layers=repr_layers, return_contacts=False)
            seq_id.extend(labels)
            for layer, t  in out['representations'].items():
                for i, label in enumerate(labels):
                    tmp = t[i, 1 : len(strs[i]) + 1].mean(0).unsqueeze(0)

分区 文献阅读 的第 87 页

                    tmp = t[i, 1 : len(strs[i]) + 1].mean(0).unsqueeze(0)
                    result[layer] =  torch.cat((result[layer], tmp),0)
    result = result[repr_layers[0]].detach().numpy()
    return seq_id, result

def get_label(seq_id, min_seq = 50):
    Label_ID = []
    for ID in seq_id:
        protein_id, src, arg_classes = ID.split("|")
        Label_ID.append(arg_classes.split(";"))
    mlb = MultiLabelBinarizer()
    Label_ID = mlb.fit_transform(Label_ID)
    ARG_Category = mlb.classes_
    if(ARG_Category.shape[0] < 2):
        print("Error: The number of category is less than 2!")
        return
    if(ARG_Category.shape[0] > 2):
        arg_freq = Label_ID.sum(axis = 0)  # 根据蛋白功能频率筛选低频ARG
        rare_id = np.where(arg_freq < min_seq)[0]

        nonarg_id = np.where(ARG_Category=="nonARG")[0]
        multi_drug_id = np.where(ARG_Category=="multi -drug")[0]
        others_id = np.where(ARG_Category == "antibiotic without defined classification")[0]
        others_id = np.append(np.append(rare_id, multi_drug_id), others_id)

        others_arg = Label_ID[:,others_id].sum(axis=1) # 蛋白的其它术语计数
        others_arg = np.where(others_arg>0, 1, others_arg)
        nonarg = Label_ID[:,nonarg_id]
        arg = 1-nonarg
        # delete nonARG and rare arg colunms
        Label_ID = np.delete(Label_ID, np.append(others_id,nonarg_id), axis=1)
        ARG_Category = np.delete(ARG_Category, np.append(others_id,nonarg_id), axis=0)
        # add others, ARG, nonARG colums
        Label_ID = np.insert(Label_ID, Label_ID.shape[1], values=[others_arg],axis = 1)
        #Label_ID = np.insert(Label_ID, 0, values=[[nonarg]],axis = 1)
        Label_ID = np.insert(Label_ID, 0, values=[[arg]],axis = 1)
        ARG_Category = np.insert(ARG_Category, ARG_Category.shape[0], "others",axis=0)
    return Label_ID, ARG_Category

分区 文献阅读 的第 88 页

HMD-ARG：用于注释抗生素耐药基因的分层多任务深度学习

2024年5月28日

21:50