

uwsdi程序，



分区 刘畅乐 的第 271 页

模型搭建日志

2024年8月19日

17:35



8月19号

使用最简单的Dense层训练，发现不平衡现象仍然存在，F1-score低。

使用Conv看，效果如何，效果变好

使用DeepARG的构架如何？密集层，考虑比特分数

ARGNet和DeepARG在uniprot上表现如何，ARGNet更可靠。这跟训练集的扩充有关

为什么ARGNet用了无监督的方法？DHR也是无监督？

无监督对不平衡问题的效果好？能发现新的ARG？

答：ARGNet中的autoencoder使用无监督方法，在ARG上训练并还原ARG，没有用标签信

息，是无监督。DHR是有标签的对比学习，目的是发现同源序列，是有监督。

明天看看DHR的模型构架，do_retrieval.py，对比学习怎么用？

8月25日

接下来的几步：

1.

复杂化模型

a.

b.

c.

比较add和并行的区别

尝试row_softmax

加入Sequential_3：self-Attention

rank的思路进行分类？

对比学习的

在GPU上训练效果变差？在排除batch_size和row_softmax后，原因是求loss时，没有用
logits
kernel size 大于 channel length，卷积没起到该有的作用。调整后，loss变小

后来又把padding=same删去，

2.

3.

1.

2.

3.

思考：在训练模型时，如何科学保存日志和模型

1.

2.

3.

4.

使用tensorboard每次加载模型和效果

统一用opt

from torchsummary import summary

一文看懂如何使用 Hydra 框架高效地跑各种超参数配置的深度学习实验 - No.22的文章 -

知乎
https://zhuanlan.zhihu.com/p/662221581
深度学习科研，如何高效进行代码和实验管理？ - 叶小飞的回答 - 知乎
https://www.zhihu.com/question/269707221/answer/2281374258

import time starttime = time.strftime("%Y-%m-%d_%H:%M:%S")#时间格式可以自定义，如

果需要定义到分钟记得改下冒号，否则输入logdir时候会出问题 print("Start

experiment:", starttime)#定义实验时间 writer =
SummaryWriter(log_dir="./log/"+starttime[:13],comment=starttime[:13],flush_secs=
60)#以实验时间命名，[:13]可以自定义，我是定义到小时基本能确定是哪个实验了

8月26日
1.

调试Focal loss的gamma，似乎gamma越小，F1score越大

思考：

1.

在调整超参数时，如何构建模块，同时运行多个参数的model？

目前想法是把opt单独拆开到一个文件中，搭建成类

2.

后台运行出现困难，不知道如何保存日志

再看看论文吧

8月27日
1.

一维卷积怎么搭配，能提取长文本的信息？

2.

3.

Attention怎么搭配CNN用，提升效果？

torch

8月29日

网络问题还没有解决，暂时解决不了了，因为师兄师姐放假。

base_channels 逐层变小：通常用于防止过拟合、减少计算开销，或在任务中特意聚焦更精细特征

